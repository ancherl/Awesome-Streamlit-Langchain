import streamlit as st

import matplotlib.pyplot as plt

from langchain_openai import ChatOpenAI

from langchain.schema import AIMessage, HumanMessage, SystemMessage

import pandas as pd
# import langchain pandas analysis engine
from langchain_experimental.agents import create_pandas_dataframe_agent

import time

import re

def stream_data(ai_message):
    for word in ai_message.split(' '):
        yield word + ' '
        time.sleep(0.02)

# define matplotlib figure process function
# def process_matplotlib_code(agent_output):
#     # 1. å‰¥ç¦» å‡€åŒ–ä»£ç å—
#     code = agent_output
#     code_block = code

#     # 2. æ­£åˆ™è¡¨è¾¾å¼å¤„ç†
#     matches = re.findall("```(?:python)?\n?([^`]+)```", code, flags=re.DOTALL)

#     if matches:
#         code_block = matches[0]
    
#     # 3. å»æ‰plt.show() ä»£ç 
#     code_block = "\n".join(l for l in code_block.splitlines() if "plt.show()" not in l)
#     with st.expander("LLM è‡ªåŠ¨ç”Ÿæˆçš„ä»£ç ï¼Œå¯æ‰‹åŠ¨æŸ¥çœ‹/å¤åˆ¶", expanded=False):
#         st.code(code_block, language="python")
#     # 4. æœ¬åœ°å˜é‡ç©ºé—´æ‰§è¡Œä»£ç å¹¶è¾“å‡ºå›¾ç‰‡
#     fig = plt.figure()
#     try:
#         exec(code_block, {"df": df, "plt": plt})
#         st.pyplot(fig)
#     except Exception as e:
#         st.error(f'ä»£ç æ‰§è¡Œé”™è¯¯: {e}')
#     finally:
#         plt.close(fig)

# Config Page Information
st.set_page_config(page_title='Homepage', layout='wide')

st.title('Welcome to Kris\'s AI Chatbox ğŸ˜')


# Initialize that ChatOpenAI object
chat = None

if 'OPENAI_MODEL_NAME' not in st.session_state:
    st.session_state['OPENAI_MODEL_NAME'] = 'gpt-4o-mini'
if 'OPENAI_TEMPERATURE' not in st.session_state:
    st.session_state['OPENAI_TEMPERATURE'] = 0.97
if 'ATTACHED_FILES' not in st.session_state:
    st.session_state['ATTACHED_FILES'] = []

if 'OPENAI_API_KEY' not in st.session_state:
    st.warning('Please config your OpenAI API Key before using GPT function!',icon='âš ')
    st.stop()
    

# åˆå§‹åŒ–chat instance
try:
    chat = ChatOpenAI(
        openai_api_key = st.session_state['OPENAI_API_KEY'],
        model=st.session_state['OPENAI_MODEL_NAME'],
        temperature=st.session_state['OPENAI_TEMPERATURE'],
    )
except Exception as e:
    st.error('OpenAI chat instance initialize exception, make sure you have provided valid open api key!')
    st.stop()

# if 'PINECONE_API_KEY' not in st.session_state:
#     st.session_state['PINECONE_API_KEY'] = ''

# if 'PINECONE_ENVIRONMENT' not in st.session_state:#     st.session_state['PINECONE_ENVIRONMENT'] = ''
# æ’å…¥ä¿©ä¸ªcontainer åˆ†åˆ«æ˜¾ç¤ºOpen AI å’Œ Pinecone çš„ ä¿¡æ¯

# with st.container():
#     st.header('OpenAI Settings')
#     st.markdown(f"""
#         | OpenAI API Key |
#         | ----------  |
#         | {st.session_state['OPENAI_API_KEY']}   |
#     """)

# with st.container():
#     st.header('Pinecone Settings')
#     st.markdown(f"""
#         | Pinecone API Key |
#         | ----------  |
#         | {st.session_state['PINECONE_API_KEY']}   |
#     """)

# æ˜¾ç¤ºå†å²å¯¹è¯è®°å½•ï¼Œéœ€è¦é€šè¿‡session state è¿›è¡Œå­˜å‚¨
if 'messages' not in st.session_state:
    st.session_state['messages'] = []


# æ ¹æ®user input è°ƒç”¨LLMåˆ†æ
if chat is not None:
    # Insert a chatbox input at the bottom
    prompt = st.chat_input('Type something you want to ask...', accept_file=True, file_type=['xlsx'])
    with st.container():
        st.header('Chat with GPT')
        # éå†session state å¯¹è¯å†å²
        for message in st.session_state['messages']:
            if isinstance(message, HumanMessage):
                with st.chat_message('user'):
                    st.markdown(message.content)
            elif isinstance(message, AIMessage):
                with st.chat_message('assistant'):
                    st.markdown(message.content)
        
        # asked = st.button('Ask')
        if prompt and (prompt['files'] or st.session_state['ATTACHED_FILES']):
            st.session_state['messages'].append(HumanMessage(content=prompt.text))
            with st.chat_message('user'):
                st.markdown(prompt.text)
            # Need to analyze the uploaded file
            # 1. Store the uploaded file in session state
            if prompt['files']:
                st.session_state['ATTACHED_FILES'] = prompt['files']
            # 2. Read the file and convert it to a pandas dataframe
            dfs = pd.read_excel(st.session_state['ATTACHED_FILES'][0], sheet_name=None)
            # 3. Initialize agent instance
            agent = create_pandas_dataframe_agent(
                    chat, 
                    [v for k, v in dfs.items()], 
                    verbose=True,
                    # handle_parsing_errors=True,
                    allow_dangerous_code=True,
            )

            # user_prompt = f"""
            #                     You are a data analysis assistant, please help me to analyze the data and provide the result.\n
            #                     If user ask you to generate a visualization chart against the data, please only output runnable matplotlib drawing code directly. Do not explain for this generated Matplotlib code, do not use plt.show(), I will use streamlit to render this chart. The data is in DataFrame list {[v for k, v in dfs.items()]}\n
            #                     Task: {prompt.text}\n
            # """
            with st.spinner('Querying...', show_time=True):
                # querying resources using LLMs
                ai_message = agent.invoke(prompt.text)
                # ai_message = agent.invoke(user_prompt)
                # st.write(ai_message)
            with st.spinner('Generating...'):
                st.session_state['messages'].append(AIMessage(content=ai_message['output']))
                # st.write(ai_message.content)
                with st.chat_message('assistant'):
                    # st.markdown(ai_message.content)
                    st.write_stream(stream_data(ai_message=ai_message['output']))
            st.stop()
        elif prompt and prompt.text:
            # Insert user input into session state
            st.session_state['messages'].append(HumanMessage(content=prompt.text))
            with st.chat_message('user'):
                st.markdown(prompt.text)
            
            with st.spinner('Querying...', show_time=True):
                # querying resources using LLMs
                ai_message = chat([HumanMessage(content=prompt.text)])
            with st.spinner('Generating...'):
                # Insert AI output into session state
                st.session_state['messages'].append(ai_message)
                # st.write(ai_message.content)
                with st.chat_message('assistant'):
                    # st.markdown(ai_message.content)
                    st.write_stream(stream_data(ai_message=ai_message.content))
            st.stop()
else:
    with st.container():
        st.warning('Please config your OpenAI API Key before using GPT function!',icon='âš ')